{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Servat0r/ISPR-Midterms-2023/blob/master/Midterm3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02PlgxCdOFnQ"
      },
      "source": [
        "# Midterm 3 ISPR 2023 - Assignment 2 - Salvatore Correnti (matr. 584136)\n",
        "In this assignment we will design and test on the `CIFAR-10` dataset a custom Convolutional Neural Network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPTIaWC1Oagi"
      },
      "source": [
        "## Initial Imports\n",
        "As usual, we start with a couple of cells for changing working directory and for all necessary imports before actually starting coding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXiKJob1NxTy",
        "outputId": "b53de509-c63c-41ef-d5b1-d7a788cf33e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/ISPR-Midterms-2023\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/Colab Notebooks/ISPR-Midterms-2023\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4dq3HZSOo1Y",
        "ExecuteTime": {
          "end_time": "2023-04-30T17:45:14.491337800Z",
          "start_time": "2023-04-30T17:45:14.469032100Z"
        },
        "outputId": "07a96a26-3508-4ebf-cdab-6b02fad96919"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Impossibile trovare il percorso specificato.\n"
          ]
        }
      ],
      "source": [
        "# Below is just to make sure we can build Tensorflow with GPU and to avoid a verbose output for installation\n",
        "!pip install tensorflow 1> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfoa9Kn_QztJ",
        "ExecuteTime": {
          "end_time": "2023-05-01T11:11:55.897978100Z",
          "start_time": "2023-05-01T11:11:49.094079300Z"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-MUf7CFQEh_"
      },
      "source": [
        "## CIFAR-10 Dataset\n",
        "For training and evaluating our Convolutional Neural Network, we will use the `CIFAR-10` dataset, which is made up of $50,000$ train and $10,000$ test $32 \\times 32$ RGB images, and is available in `keras` as a \"built-in\" dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nP0yXjMaP9x8",
        "ExecuteTime": {
          "end_time": "2023-05-01T11:12:03.577680600Z",
          "start_time": "2023-05-01T11:11:58.920411500Z"
        }
      },
      "outputs": [],
      "source": [
        "(x_dev, y_dev), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# Show an image as an example\n",
        "exampleImage = Image.fromarray(x_dev[0], mode='RGB')\n",
        "exampleImage = exampleImage.resize((64, 64))  # Just to show it better\n",
        "exampleImage.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_zSPHgKdIDV"
      },
      "source": [
        "We now convert CIFAR-10 labels into `one-hot` format for usage with a \"Sotfmax-based\" CNN classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7L5_9glRS2i",
        "outputId": "7ca74639-69e6-4057-fedc-245b12b557dd",
        "ExecuteTime": {
          "end_time": "2023-05-01T11:12:07.418850100Z",
          "start_time": "2023-05-01T11:12:07.403462500Z"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": "array([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32)"
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_dev = to_categorical(y_dev)\n",
        "y_test = to_categorical(y_test)\n",
        "y_dev[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before proceeding, we also normalize pixel values into the range $[0, 1]$ and we split training data into properly training ones and validation ones (we will keep test data to evaluate the final model)."
      ],
      "metadata": {
        "collapsed": false,
        "id": "Z9VQ8FRD-bW1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "x_dev = x_dev.astype(np.float32) / 255\n",
        "x_test = x_test.astype(np.float32) / 255\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_eval, y_train, y_eval = train_test_split(x_dev, y_dev, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-01T11:12:15.394319Z",
          "start_time": "2023-05-01T11:12:13.838422800Z"
        },
        "id": "nOtiq64F-bW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Designing a Convolutional Neural Network for CIFAR-10\n",
        "When designing a custom Convolutional Neural Network for a specific task, it is important to take into account at least the most important \"building blocks\" for CNNs that have been developed through the years and used in \"reference\" models. Indeed, since CNNs are in usage by about a decade, it is convenient to take inspiration or directly modify one of these reference models to achieve our objectives. Also, monitoring the accuracy and the space and time required for training a given model (e.g. by calculating the number of parameters) is also fundamental, and in particular since we don't have required hardware for huge models we want to get a tradeoff between accuracy and size of the model.\n",
        "\n",
        "We will then go through our discussion throughout the following design choices:\n",
        "\n",
        "1. `Target Accuracy`: we want to achieve an accuracy at least $\\geq 70\\%$, since this is the accuracy that one can easily get with a \"reduced\" `VGG` model (see below). On top of that, we can consider additional design choices based on what we get from experiments for achieving a higher one;\n",
        "2. `\"Style\" of the CNN`: we will use the \"traditional\" design pattern of a series of Convolutional-MaxPooling layers, ended by a `Fully-Connected` block and `Softmax` activation, as employed in `AlexNet`, `VGG` and (apart from MaxPool) in `GoogLeNet`;\n",
        "3. `Base Model`: since `CIFAR-10` images are of size $32 \\times 32$, we are not interested in very deep networks for reducing the feature maps sizes up to reasonable values for usage with a final sequence of fully-connected layers, or in other words if we use `max-pooling` with a pool size of $(2, 2)$, it suffices to employ $3$ `MaxPool2D` layers to get a feature map of size $\\leq 4 \\times 4$, and if we suppose to have $N$ filters at the end, we will get $16N$ input units for the `dense` part of the network, which can be reasonable if we take for example a single hidden layer with a size $\\leq 128$, or we directly skip the `dense hidden` layers. As a consequence, we will model our CNNs as a sort of \"reduced\" version of `VGG`, which has proved to be quite effective in classification tasks over `ImageNet`;\n",
        "4. `Number of Parameters`: ideally, we want to keep $< 1,000,000$ parameters for our Convolutional Neural Network, which is suitable for a 2-deep or 3-deep (in the sense of Conv2D-MaxPool blocks) `VGG-like` network. After having built a \"satisfactory\" network without explicit design choices for restricting the number of parameters, we can explore usage of $1 \\times 1$ convolutions and reduced `Dense` blocks to reduce the number of parameters while retaining most of the accuracy;\n",
        "5. `Regularization`: since a `VGG-like` CNN can quickly become quite big, especially in the `Dense` part, it is essential to adopt regularization strategies to limit overfitting and improving overall performance. From an architectural point of view, two viable yet effective strategies are `Dropout` and `Batch Normalization`, and we will experiment with both of them to see if we can improve overall performance of the network;\n",
        "6. `Advanced Blocks`: if we manage to keep our network \"sufficiently small\" (i.e. with 2 or 3 Conv2D-MaxPool blocks), we may not use advanced architectural patterns like `Skip Connections` and `Inception Blocks`, which complicate the design and coding of the Neural Network, especially if we can keep under control `vanishing gradient` phenomena by avoiding a too deep network."
      ],
      "metadata": {
        "collapsed": false,
        "id": "64tMGtd5-bW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VGG Network\n",
        "<img src=\"vgg16.png\">\n",
        "\n",
        "**`VGG16`** (**`Visual Geometry Group 16`**) network was developed in (?) by (?) and won the (?) competition on the `ImageNet` dataset. As we can see in the above figure, VGG16 is composed by a sequence of $5$ `Conv2D-Conv2D-MaxPool` blocks, i.e. 2 Convolutional Layers with `same` padding and $3 \\times 3$ kernel sizes, followed by a single MaxPooling layer with pool size of $2 \\times 2$ for reducing feature maps sizes. As we can see, each block contains 2 Convolutional Layer with an increasing number of filters for each one ($64$, $128$, $256$, $512$, $512$) and a single hidden layer of size $4096$.\n",
        "\n",
        "The idea behind this pattern is that by reducing the size of the feature maps we are progressively representing \"higher-level\" features that somehow \"summarize\" information by lower-level ones, hence the number of \"descriptors\" we want to keep should be increasing when we traverse the network, and moreover we want to let \"feature descriptors\" from more and more distant areas of the image to combine themselves."
      ],
      "metadata": {
        "collapsed": false,
        "id": "yOsb3h6p-bW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Reduced VGG\n",
        "We can keep the above design pattern in our CNN by simply reducing the number of Blocks and the size of the hidden layer, or by removing it at all. For example, we can employ a first block made up of two convolutional layers each one with $32$ filters of size $3 \\times 3$, a second one with $64$ filters and a third one of $128$ ones. As in VGG16, we use `same` padding even if it may introduce some form of bias due to the padding value since we are using a very small kernel.\n",
        "\n",
        "We will start with a \"simple\" Reduced VGG without any Dropout, Batch Normalization or Dense Hidden Layer to see if this is a viable baseline."
      ],
      "metadata": {
        "collapsed": false,
        "id": "O6OmKM-A-bW2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enJZJ0JBTa0Q",
        "ExecuteTime": {
          "end_time": "2023-05-01T11:12:29.800038100Z",
          "start_time": "2023-05-01T11:12:29.783254600Z"
        }
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, BatchNormalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 307,498\n",
            "Trainable params: 307,498\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "baseReducedVGG = Sequential()\n",
        "\n",
        "baseReducedVGG.add(Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=(32,32,3), padding='same'))\n",
        "baseReducedVGG.add(Conv2D(32, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "baseReducedVGG.add(MaxPool2D())\n",
        "\n",
        "baseReducedVGG.add(Conv2D(64, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "baseReducedVGG.add(Conv2D(64, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "baseReducedVGG.add(MaxPool2D())\n",
        "\n",
        "baseReducedVGG.add(Conv2D(128, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "baseReducedVGG.add(Conv2D(128, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "baseReducedVGG.add(MaxPool2D())\n",
        "\n",
        "# Now we flatten for fully-connected part\n",
        "baseReducedVGG.add(Flatten())\n",
        "baseReducedVGG.add(Dense(10, activation=\"softmax\"))\n",
        "baseReducedVGG.summary()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-30T17:48:39.418950300Z",
          "start_time": "2023-04-30T17:48:39.281573100Z"
        },
        "id": "BDbHVmBL-bW3",
        "outputId": "acb0bca4-9bf8-4637-caaf-61058a71ef82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, our `baseReducedVGG` model has $307,498$ parameters, which is a reasonable amount and far below the $1,000,000$ maximum we mentioned before. We also notice that since we have not used any Dense hidden layer, the two Conv2D layers with $128$ filters contribute for $\\approx 75\\%$ of the total parameters, hence we will not use any higher number of filters to keep number of parameters (hence training time) under control.\n",
        "\n",
        "We now compile and train the model with a batch size of $64$ and for $10$ epochs, using `Adam` optimizer and `Categorical Cross Entropy` loss:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "CCDnT8bH-bW3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2PtW7sYg-x0",
        "ExecuteTime": {
          "end_time": "2023-04-30T17:51:19.376790200Z",
          "start_time": "2023-04-30T17:51:19.361901600Z"
        }
      },
      "outputs": [],
      "source": [
        "baseReducedVGG.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZlQbXYZhJJ_",
        "outputId": "99402370-6ab1-40e7-e8cb-a041fec02ec6",
        "ExecuteTime": {
          "end_time": "2023-04-30T18:05:28.421138Z",
          "start_time": "2023-04-30T17:52:06.567841900Z"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 78s 123ms/step - loss: 1.5676 - accuracy: 0.4262 - val_loss: 1.2576 - val_accuracy: 0.5510\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 77s 123ms/step - loss: 1.0678 - accuracy: 0.6219 - val_loss: 0.9501 - val_accuracy: 0.6671\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 77s 123ms/step - loss: 0.8487 - accuracy: 0.7031 - val_loss: 0.8160 - val_accuracy: 0.7160\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 81s 129ms/step - loss: 0.6961 - accuracy: 0.7577 - val_loss: 0.7427 - val_accuracy: 0.7410\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 81s 130ms/step - loss: 0.5838 - accuracy: 0.7975 - val_loss: 0.7546 - val_accuracy: 0.7457\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 83s 132ms/step - loss: 0.4889 - accuracy: 0.8299 - val_loss: 0.7460 - val_accuracy: 0.7543\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.3984 - accuracy: 0.8624 - val_loss: 0.7304 - val_accuracy: 0.7634\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 81s 130ms/step - loss: 0.3282 - accuracy: 0.8829 - val_loss: 0.7984 - val_accuracy: 0.7600\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 80s 128ms/step - loss: 0.2548 - accuracy: 0.9099 - val_loss: 0.8889 - val_accuracy: 0.7575\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 82s 131ms/step - loss: 0.2006 - accuracy: 0.9287 - val_loss: 0.9072 - val_accuracy: 0.7658\n"
          ]
        }
      ],
      "source": [
        "baseReducedVGGHistory = baseReducedVGG.fit(\n",
        "    x_train, y_train, validation_data=(x_eval, y_eval), epochs=10, batch_size=64,\n",
        "    callbacks=[tf.keras.callbacks.CSVLogger('baseReducedVGG_log.csv')],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyO9VVjDhFYt"
      },
      "source": [
        "As we can see, we already got a very high training accuracy ($92.87\\%$) and a quite high validation one ($76.58\\%$). From the results of the last $3$ epochs we also notice that validation accuracy is substantially stalling in the interval $[0.75, 0.77]$, so we may imagine that we are reaching an overfitting point. As already said, this test is to actually verify that a \"base\" ReducedVGG actually works well with CIFAR-10. We now move onto adding Dropout and Batch Normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adding Dropout and Batch Normalization\n",
        "We will add a `BatchNormalization` layer after each Convolutional, MaxPooling and non-output Dense layer, since we want to avoid each possible \"internal shift\" in the distribution that the network is learning. By contrary, we can add Dropout layers after each Conv2D-MaxPool block, since we do not have any trainable parameter in Dropout layers and moreover its effect as regularizer is actually to train an implicit emsembler of subnetworks inside the original one, and we do not want to \"fragment\" too much the network; in particular, we want to keep Conv2D-MaxPool blocks as \"units\" for the underlying subnetworks.\n",
        "\n",
        "We do not want to do any hyperparameter tuning by now, hence we set Dropout probabilities to standard values of $0.2$ and $0.3$, paying attention to the fact that as we increase the number of filters and hence the number of parameters we want a higher regularization effect, hence a higher Dropout probability."
      ],
      "metadata": {
        "collapsed": false,
        "id": "SPj53kIR-bW4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 4, 4, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 2048)             8192      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 318,378\n",
            "Trainable params: 312,938\n",
            "Non-trainable params: 5,440\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "regularizedReducedVGG = Sequential()\n",
        "\n",
        "regularizedReducedVGG.add(Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=(32,32,3), padding='same'))\n",
        "regularizedReducedVGG.add(BatchNormalization())\n",
        "regularizedReducedVGG.add(Conv2D(32, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "regularizedReducedVGG.add(BatchNormalization())\n",
        "regularizedReducedVGG.add(MaxPool2D())\n",
        "regularizedReducedVGG.add(BatchNormalization())\n",
        "regularizedReducedVGG.add(Dropout(0.2))\n",
        "\n",
        "regularizedReducedVGG.add(Conv2D(64, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "regularizedReducedVGG.add(BatchNormalization())\n",
        "regularizedReducedVGG.add(Conv2D(64, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "regularizedReducedVGG.add(BatchNormalization())\n",
        "regularizedReducedVGG.add(MaxPool2D())\n",
        "regularizedReducedVGG.add(BatchNormalization())\n",
        "regularizedReducedVGG.add(Dropout(0.3))\n",
        "\n",
        "regularizedReducedVGG.add(Conv2D(128, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "regularizedReducedVGG.add(BatchNormalization())\n",
        "regularizedReducedVGG.add(Conv2D(128, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "regularizedReducedVGG.add(BatchNormalization())\n",
        "regularizedReducedVGG.add(MaxPool2D())\n",
        "regularizedReducedVGG.add(BatchNormalization())\n",
        "regularizedReducedVGG.add(Dropout(0.3))\n",
        "\n",
        "regularizedReducedVGG.add(Flatten())\n",
        "regularizedReducedVGG.add(BatchNormalization())\n",
        "regularizedReducedVGG.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "regularizedReducedVGG.summary()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-30T18:38:57.766735100Z",
          "start_time": "2023-04-30T18:38:57.509624200Z"
        },
        "id": "F4QwXHcD-bW4",
        "outputId": "9be78dc0-4bd4-4533-f502-14505780bc8b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "regularizedReducedVGG.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-30T18:39:18.419622700Z",
          "start_time": "2023-04-30T18:39:18.396215500Z"
        },
        "id": "x4-SA84I-bW4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 109s 171ms/step - loss: 1.5031 - accuracy: 0.4895 - val_loss: 1.1002 - val_accuracy: 0.6169\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 110s 176ms/step - loss: 1.0239 - accuracy: 0.6458 - val_loss: 0.8442 - val_accuracy: 0.7082\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 107s 172ms/step - loss: 0.8675 - accuracy: 0.6997 - val_loss: 0.8589 - val_accuracy: 0.7132\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 109s 174ms/step - loss: 0.7718 - accuracy: 0.7336 - val_loss: 0.7473 - val_accuracy: 0.7458\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 106s 170ms/step - loss: 0.7045 - accuracy: 0.7577 - val_loss: 0.7910 - val_accuracy: 0.7366\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 107s 171ms/step - loss: 0.6509 - accuracy: 0.7750 - val_loss: 0.6986 - val_accuracy: 0.7672\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 107s 171ms/step - loss: 0.6002 - accuracy: 0.7927 - val_loss: 0.7227 - val_accuracy: 0.7679\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 109s 174ms/step - loss: 0.5536 - accuracy: 0.8099 - val_loss: 0.6993 - val_accuracy: 0.7742\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 119s 191ms/step - loss: 0.5293 - accuracy: 0.8152 - val_loss: 0.6434 - val_accuracy: 0.7881\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 118s 189ms/step - loss: 0.5038 - accuracy: 0.8245 - val_loss: 0.7179 - val_accuracy: 0.7711\n"
          ]
        }
      ],
      "source": [
        "regularizedReducedVGGHistory = regularizedReducedVGG.fit(\n",
        "    x_train, y_train, validation_data=(x_eval, y_eval), epochs=10, batch_size=64,\n",
        "    callbacks=[tf.keras.callbacks.CSVLogger('baseReducedVGG_log.csv')],\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-04-30T18:57:42.619132700Z",
          "start_time": "2023-04-30T18:39:20.325330100Z"
        },
        "id": "icXs8zIP-bW4",
        "outputId": "7e696cc0-2993-408a-fe38-3830196e8a8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We notice that now final training accuracy if lower than in the previous case ($82.45\\%$ against $92.87\\%$), but on the bright side we got a small improvement in the validation accuracy of about $1-2\\%$, hence we can keep Dropout and BatchNormalization inside our final network."
      ],
      "metadata": {
        "collapsed": false,
        "id": "ZlfpCNWI-bW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Adding Dense layers\n",
        "We now try to add `Dense` hidden layers in the final part of the network to see if this improves accuracy. As already seen, after Conv2D-MaxPool blocks we have $2048$ parameters in the flattened array, hence if we insert a hidden layer of size $m$, we get $2058m$ parameters. To keep the total number of parameters $< 1,000,000$, and possibly $< 500,000$ but without forcing the network to \"simplify\" too much the representation in the flattened array, we can take a hidden size of $128$. As for the previous network, we add a BatchNormalization layer and a Dropout one after the hidden layer and we use a Dropout probability of $0.5$."
      ],
      "metadata": {
        "collapsed": false,
        "id": "cL1XqFBI-bW5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 32, 32, 32)       128       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 32, 32, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 16, 16, 32)       128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 16, 16, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 8, 8, 64)         256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 8, 8, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 4, 4, 128)        512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 2048)             8192      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               262272    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 561,962\n",
            "Trainable params: 556,266\n",
            "Non-trainable params: 5,696\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "dense128ReducedVGG = Sequential()\n",
        "\n",
        "dense128ReducedVGG.add(Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=(32,32,3), padding='same'))\n",
        "dense128ReducedVGG.add(BatchNormalization())\n",
        "dense128ReducedVGG.add(Conv2D(32, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "dense128ReducedVGG.add(BatchNormalization())\n",
        "dense128ReducedVGG.add(MaxPool2D())\n",
        "dense128ReducedVGG.add(Dropout(0.2))\n",
        "dense128ReducedVGG.add(BatchNormalization())\n",
        "\n",
        "dense128ReducedVGG.add(Conv2D(64, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "dense128ReducedVGG.add(BatchNormalization())\n",
        "dense128ReducedVGG.add(Conv2D(64, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "dense128ReducedVGG.add(BatchNormalization())\n",
        "dense128ReducedVGG.add(MaxPool2D())\n",
        "dense128ReducedVGG.add(Dropout(0.3))\n",
        "dense128ReducedVGG.add(BatchNormalization())\n",
        "\n",
        "dense128ReducedVGG.add(Conv2D(128, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "dense128ReducedVGG.add(BatchNormalization())\n",
        "dense128ReducedVGG.add(Conv2D(128, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "dense128ReducedVGG.add(BatchNormalization())\n",
        "dense128ReducedVGG.add(MaxPool2D())\n",
        "dense128ReducedVGG.add(Dropout(0.3))\n",
        "dense128ReducedVGG.add(BatchNormalization())\n",
        "\n",
        "dense128ReducedVGG.add(Flatten())\n",
        "dense128ReducedVGG.add(BatchNormalization())\n",
        "dense128ReducedVGG.add(Dense(128, activation=\"relu\", kernel_initializer=\"he_uniform\", bias_initializer=\"he_uniform\"))\n",
        "dense128ReducedVGG.add(Dropout(0.5))\n",
        "dense128ReducedVGG.add(BatchNormalization())\n",
        "dense128ReducedVGG.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "dense128ReducedVGG.summary()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-01T11:12:41.513249900Z",
          "start_time": "2023-05-01T11:12:41.152960400Z"
        },
        "id": "niA8baMe-bW5",
        "outputId": "e2394dfd-8abe-4b14-efe3-a1a858c7fb21"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "dense128ReducedVGG.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-01T11:13:06.502830700Z",
          "start_time": "2023-05-01T11:13:06.482757Z"
        },
        "id": "ImtqBTw--bW5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 109s 170ms/step - loss: 1.5771 - accuracy: 0.4438 - val_loss: 1.3246 - val_accuracy: 0.5331\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 107s 170ms/step - loss: 1.0837 - accuracy: 0.6162 - val_loss: 0.8731 - val_accuracy: 0.6914\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 113s 182ms/step - loss: 0.9240 - accuracy: 0.6762 - val_loss: 0.8488 - val_accuracy: 0.6973\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 115s 184ms/step - loss: 0.8226 - accuracy: 0.7140 - val_loss: 0.6994 - val_accuracy: 0.7535\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 112s 179ms/step - loss: 0.7564 - accuracy: 0.7364 - val_loss: 0.6965 - val_accuracy: 0.7575\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 112s 179ms/step - loss: 0.6922 - accuracy: 0.7615 - val_loss: 0.6474 - val_accuracy: 0.7797\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 112s 180ms/step - loss: 0.6450 - accuracy: 0.7767 - val_loss: 0.6834 - val_accuracy: 0.7649\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 112s 179ms/step - loss: 0.6017 - accuracy: 0.7934 - val_loss: 0.5542 - val_accuracy: 0.8073\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 105s 168ms/step - loss: 0.5649 - accuracy: 0.8063 - val_loss: 0.5479 - val_accuracy: 0.8092\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 109s 175ms/step - loss: 0.5331 - accuracy: 0.8149 - val_loss: 0.5253 - val_accuracy: 0.8221\n"
          ]
        }
      ],
      "source": [
        "dense128ReducedVGGHistory = dense128ReducedVGG.fit(\n",
        "    x_train, y_train, validation_data=(x_eval, y_eval), epochs=10, batch_size=64,\n",
        "    callbacks=[tf.keras.callbacks.CSVLogger('baseReducedVGG_log.csv')],\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-01T11:32:03.089532600Z",
          "start_time": "2023-05-01T11:13:35.709942200Z"
        },
        "id": "2TQexqas-bW5",
        "outputId": "fac4dc3a-d31c-4cf9-9d18-d4e0fd319013"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, we got an improvement in validation accuracy of about $5\\%$, while training one is stable. We can then keep the hidden Dense layer of size $128$ and test the final model on the Test Set.\n",
        "\n",
        "We now evaluate the model over the Test Set:"
      ],
      "metadata": {
        "collapsed": false,
        "id": "jhfNLqe5-bW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To summarize, our custom Convolutional Neural Network has the following structure:\n",
        "* A sequence of two **Convolutional Layers** with $32$ filters of size $3 \\times 3$ with `same` padding and **Batch Normalization** after each layer;\n",
        "* A **MaxPool** layer of pooling size of $2 \\times 2$, followed by a **Dropout** layer with a (default) dropout probability of $0.2$ and another **Batch Normalization** one;\n",
        "* A sequence of two **Convolutional Layers** with $64$ filters of size $3 \\times 3$ with `same` padding and **Batch Normalization** after each layer;\n",
        "* A **MaxPool** layer of pooling size of $2 \\times 2$, followed by a **Dropout** layer with a (default) dropout probability of $0.3$ and another **Batch Normalization** one;\n",
        "* A sequence of two **Convolutional Layers** with $128$ filters of size $3 \\times 3$ with `same` padding and **Batch Normalization** after each layer;\n",
        "* A **MaxPool** layer of pooling size of $2 \\times 2$, followed by a **Dropout** layer with a (default) dropout probability of $0.3$ and another **Batch Normalization** one;\n",
        "* After that, the output is flattened to an array of size $2048$ and forwarded to a **Dense** layer of size $2048 \\times 128$;\n",
        "* Finally, we have another **Dense** layer of size $128 \\times 10$ and a **Softmax** layer for outputting probability distributions over the $10$ classes for the given input.\n",
        "\n",
        "Our network is a sort of `\"ReducedVGG\"` in the sense that follows the architectural pattern of `VGG16`, but it adapts it to the smaller size of `CIFAR-10` images and introduces `Dropout` and `BatchNormalization` for having regularization and robustness against internal distribution shifts. We have used neither any Skip or Residual Connections nor any `Inception` module to keep the model simple ($561,962$ parameters) while still retaining a good accuracy in the range $80-82\\%$."
      ],
      "metadata": {
        "collapsed": false,
        "id": "LtB8NQ-h-bW5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_40 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_72 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_41 (Conv2D)          (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_73 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_20 (MaxPoolin  (None, 16, 16, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_26 (Dropout)        (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_74 (Bat  (None, 16, 16, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_42 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_75 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_43 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_76 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_21 (MaxPoolin  (None, 8, 8, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_27 (Dropout)        (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " batch_normalization_77 (Bat  (None, 8, 8, 64)         256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_44 (Conv2D)          (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_78 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_45 (Conv2D)          (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_79 (Bat  (None, 8, 8, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_22 (MaxPoolin  (None, 4, 4, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_28 (Dropout)        (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_80 (Bat  (None, 4, 4, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_46 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_81 (Bat  (None, 4, 4, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_47 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_82 (Bat  (None, 4, 4, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_23 (MaxPoolin  (None, 2, 2, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " batch_normalization_83 (Bat  (None, 2, 2, 128)        512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_84 (Bat  (None, 512)              2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization_85 (Bat  (None, 256)              1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 723,370\n",
            "Trainable params: 719,722\n",
            "Non-trainable params: 3,648\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "dense256ReducedVGG = Sequential()\n",
        "\n",
        "dense256ReducedVGG.add(Conv2D(32, kernel_size=3, activation=\"relu\", input_shape=(32, 32, 3), padding='same'))\n",
        "dense256ReducedVGG.add(BatchNormalization())\n",
        "dense256ReducedVGG.add(Conv2D(32, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "dense256ReducedVGG.add(BatchNormalization())\n",
        "dense256ReducedVGG.add(MaxPool2D())\n",
        "dense256ReducedVGG.add(Dropout(0.3))\n",
        "dense256ReducedVGG.add(BatchNormalization())\n",
        "\n",
        "dense256ReducedVGG.add(Conv2D(64, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "dense256ReducedVGG.add(BatchNormalization())\n",
        "dense256ReducedVGG.add(Conv2D(64, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "dense256ReducedVGG.add(BatchNormalization())\n",
        "dense256ReducedVGG.add(MaxPool2D())\n",
        "dense256ReducedVGG.add(Dropout(0.3))\n",
        "dense256ReducedVGG.add(BatchNormalization())\n",
        "\n",
        "dense256ReducedVGG.add(Conv2D(128, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "dense256ReducedVGG.add(BatchNormalization())\n",
        "dense256ReducedVGG.add(Conv2D(128, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "dense256ReducedVGG.add(BatchNormalization())\n",
        "dense256ReducedVGG.add(MaxPool2D())\n",
        "dense256ReducedVGG.add(Dropout(0.3))\n",
        "dense256ReducedVGG.add(BatchNormalization())\n",
        "\n",
        "dense256ReducedVGG.add(Conv2D(128, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "dense256ReducedVGG.add(BatchNormalization())\n",
        "dense256ReducedVGG.add(Conv2D(128, kernel_size=3, activation=\"relu\", padding='same'))\n",
        "dense256ReducedVGG.add(BatchNormalization())\n",
        "dense256ReducedVGG.add(MaxPool2D())\n",
        "dense256ReducedVGG.add(Dropout(0.3))\n",
        "dense256ReducedVGG.add(BatchNormalization())\n",
        "\n",
        "dense256ReducedVGG.add(Flatten())\n",
        "dense256ReducedVGG.add(BatchNormalization())\n",
        "dense256ReducedVGG.add(Dense(256, activation=\"relu\", kernel_initializer=\"he_uniform\", bias_initializer=\"he_uniform\"))\n",
        "dense256ReducedVGG.add(Dropout(0.5))\n",
        "dense256ReducedVGG.add(BatchNormalization())\n",
        "dense256ReducedVGG.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "dense256ReducedVGG.summary()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-01T14:34:14.039933700Z",
          "start_time": "2023-05-01T14:34:13.746752300Z"
        },
        "id": "UljXmGpi-bW6",
        "outputId": "7b0622db-41b0-4e82-e7bd-0d984ab45bd7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "dense256ReducedVGG.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-01T14:34:27.465792300Z",
          "start_time": "2023-05-01T14:34:27.418199400Z"
        },
        "id": "4FmZeAb--bW6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 121s 187ms/step - loss: 1.7213 - accuracy: 0.3919 - val_loss: 1.4986 - val_accuracy: 0.4742\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 112s 179ms/step - loss: 1.1622 - accuracy: 0.5860 - val_loss: 1.0086 - val_accuracy: 0.6326\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 111s 177ms/step - loss: 0.9627 - accuracy: 0.6603 - val_loss: 0.9091 - val_accuracy: 0.6848\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 112s 179ms/step - loss: 0.8336 - accuracy: 0.7133 - val_loss: 0.9559 - val_accuracy: 0.6662\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 112s 179ms/step - loss: 0.7486 - accuracy: 0.7434 - val_loss: 0.7616 - val_accuracy: 0.7412\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 111s 178ms/step - loss: 0.6825 - accuracy: 0.7646 - val_loss: 0.6516 - val_accuracy: 0.7669\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 118s 188ms/step - loss: 0.6308 - accuracy: 0.7844 - val_loss: 0.6961 - val_accuracy: 0.7626\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 117s 187ms/step - loss: 0.5850 - accuracy: 0.7990 - val_loss: 0.6771 - val_accuracy: 0.7753\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 117s 188ms/step - loss: 0.5395 - accuracy: 0.8133 - val_loss: 0.6950 - val_accuracy: 0.7628\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 118s 189ms/step - loss: 0.5072 - accuracy: 0.8239 - val_loss: 0.5344 - val_accuracy: 0.8182\n"
          ]
        }
      ],
      "source": [
        "dense256ReducedVGGHistory = dense256ReducedVGG.fit(\n",
        "    x_train, y_train, validation_data=(x_eval, y_eval), epochs=10, batch_size=64,\n",
        "    callbacks=[tf.keras.callbacks.CSVLogger('baseReducedVGG_log.csv')],\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-01T14:53:39.391094900Z",
          "start_time": "2023-05-01T14:34:30.634355800Z"
        },
        "id": "CqikAKQm-bW6",
        "outputId": "23d2c7aa-9203-4175-dc6b-2f98b5fb3758"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 114s 183ms/step - loss: 0.4790 - accuracy: 0.8370 - val_loss: 0.5723 - val_accuracy: 0.8069\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 114s 183ms/step - loss: 0.4439 - accuracy: 0.8476 - val_loss: 0.5347 - val_accuracy: 0.8163\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 115s 184ms/step - loss: 0.4177 - accuracy: 0.8556 - val_loss: 0.5175 - val_accuracy: 0.8265\n"
          ]
        },
        {
          "data": {
            "text/plain": "<keras.callbacks.History at 0x177ff4bb3d0>"
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dense256ReducedVGG.fit(\n",
        "    x_train, y_train, validation_data=(x_eval, y_eval), epochs=3, batch_size=64,\n",
        "    callbacks=[tf.keras.callbacks.CSVLogger('baseReducedVGG_log.csv')],\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-01T15:03:04.213143600Z",
          "start_time": "2023-05-01T14:57:20.987057800Z"
        },
        "id": "-9h46qbw-bW6",
        "outputId": "3b422ce5-7c64-4bc1-9bb8-d7f8317e84f1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 126s 201ms/step - loss: 0.3931 - accuracy: 0.8637 - val_loss: 0.4998 - val_accuracy: 0.8343\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 120s 192ms/step - loss: 0.3768 - accuracy: 0.8688 - val_loss: 0.4884 - val_accuracy: 0.8389\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 126s 202ms/step - loss: 0.3597 - accuracy: 0.8771 - val_loss: 0.5435 - val_accuracy: 0.8269\n"
          ]
        },
        {
          "data": {
            "text/plain": "<keras.callbacks.History at 0x177ff72f350>"
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dense256ReducedVGG.fit(\n",
        "    x_train, y_train, validation_data=(x_eval, y_eval), epochs=3, batch_size=64,\n",
        "    callbacks=[tf.keras.callbacks.CSVLogger('baseReducedVGG_log.csv')],\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-05-01T15:09:34.648535400Z",
          "start_time": "2023-05-01T15:03:22.240218300Z"
        },
        "id": "xnIszAPn-bW6",
        "outputId": "4c08582f-a52f-4794-cdbc-305d19b7788f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [],
      "metadata": {
        "id": "Ein39CYe-bW7"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}